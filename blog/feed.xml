<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Sumedh R. Sankhe - Blog</title>
    <link>https://sumedhsankhe.github.io/blog.html</link>
    <description>Technical insights, tutorials, and thoughts on bioinformatics, R Shiny, and software engineering</description>
    <language>en-us</language>
    <lastBuildDate>Tue, 24 Dec 2025 00:00:00 GMT</lastBuildDate>
    <atom:link href="https://sumedhsankhe.github.io/blog/feed.xml" rel="self" type="application/rss+xml"/>
    <generator>Custom</generator>
    <webMaster>noreply@sumedhsankhe.github.io (Sumedh R. Sankhe)</webMaster>
    <copyright>Copyright 2025 Sumedh R. Sankhe. All rights reserved.</copyright>

    <item>
      <title>Docker Optimization Part 2: Intelligent Caching for R Shiny Applications</title>
      <link>https://sumedhsankhe.github.io/blog/posts/docker-optimization-part2.html</link>
      <guid isPermaLink="true">https://sumedhsankhe.github.io/blog/posts/docker-optimization-part2.html</guid>
      <pubDate>Tue, 24 Dec 2025 00:00:00 GMT</pubDate>
      <author>noreply@sumedhsankhe.github.io (Sumedh R. Sankhe)</author>
      <category>Docker</category>
      <category>R</category>
      <category>Shiny</category>
      <category>DevOps</category>
      <category>CI/CD</category>
      <category>GitHub Actions</category>
      <category>Testing</category>
      <description><![CDATA[
                <p class="blog-intro">In <a href="docker-optimization.html">Part 1</a>, we covered the basics of multistage builds and layer caching for R Shiny applications. The TL;DR: separate your slow-changing dependencies from fast-changing application code, and Docker's layer cache will reward you with faster builds. But that approach has a blind spot—a big one. This post explores advanced caching strategies that solve the "phantom dependency" problem and make your Docker builds even more intelligent.</p>

                <h2 id="the-problem-nobody-talks-about">The Problem Nobody Talks About</h2>

                <p>Picture this: your <code>renv.lock</code> hasn't changed in two weeks. Your Dockerfile is identical. You push a one-line bug fix. Docker sees nothing changed in the dependency layers, serves everything from cache, and your build finishes in 3 minutes. Beautiful.</p>

                <p>Except... your teammate just pushed a critical fix to an internal R package hosted on GitHub. Your build used the cached version. The fix isn't in your image. You deploy. Production breaks.</p>

                <p>This is the "phantom dependency" problem. Docker's layer cache is content-addressed—it only knows about files <em>in your repository</em>. It has no idea that <code>renv::install("org/package")</code> now points to different code than it did yesterday.</p>

                <p>We needed to solve two distinct caching problems:</p>

                <ol>
                    <li><strong>Lock file changes</strong>: When <code>renv.lock</code> updates, rebuild the base image</li>
                    <li><strong>External package changes</strong>: When upstream GitHub packages change (but lock file doesn't), invalidate just that layer</li>
                </ol>

                <p>And while we're at it, why not make tests a build gate? If tests fail, the image shouldn't exist.</p>

                <h2 id="solution-1-hash-based-base-images">Solution 1: Hash-Based Base Images</h2>

                <p>The insight is simple: treat your lock file as a cache key. Same lock file = same dependencies = reuse the image. Different hash = rebuild.</p>

                <p>Here's the mechanism:</p>

                <pre><code class="language-bash"># Compute a 12-character hash of your lock file
LOCK_HASH=$(sha256sum renv.lock | cut -c1-12)

# Tag your base image with the hash
BASE_TAG="my-app-base:${VERSION}-${LOCK_HASH}"
# Example: my-app-base:1.4-dev-a3b2c1d4e5f6</code></pre>

                <p>Now your CI workflow becomes:</p>

                <pre><code class="language-yaml">- name: Check if base image exists
  run: |
    LOCK_HASH=$(sha256sum renv.lock | cut -c1-12)
    BASE_TAG="my-app-base:${BRANCH}-${LOCK_HASH}"

    if docker pull "registry.example.com/${BASE_TAG}" 2>/dev/null; then
      echo "Base image found - using cache"
      echo "needs_build=false" >> $GITHUB_OUTPUT
    else
      echo "Base image not found - will build"
      echo "needs_build=true" >> $GITHUB_OUTPUT
    fi

- name: Build base image (if needed)
  if: steps.check.outputs.needs_build == 'true'
  run: |
    docker build -f Dockerfile.base \
      --build-arg LOCK_HASH=${LOCK_HASH} \
      -t registry.example.com/${BASE_TAG} .
    docker push registry.example.com/${BASE_TAG}</code></pre>

                <p>The base Dockerfile installs everything from your lock file:</p>

                <pre><code class="language-dockerfile"># Dockerfile.base - Stable dependency layer
FROM rocker/r2u:24.04

COPY renv.lock /app/renv.lock
COPY .Rprofile /app/.Rprofile
COPY renv/activate.R /app/renv/activate.R

WORKDIR /app

# Restore all packages from lock file
RUN R -e "renv::restore()"

# Label with hash for traceability
ARG LOCK_HASH
LABEL renv.lock.hash="${LOCK_HASH}"</code></pre>

                <p><strong>Why this works</strong>: The first PR that updates <code>renv.lock</code> pays the ~15 minute base image build cost. Every subsequent PR targeting that branch (with the same lock file) gets instant cache hits. When someone updates dependencies again, only then does the base image rebuild.</p>

                <p>In practice, we saw base image rebuilds drop from "every PR" to "2-3 times per release cycle."</p>

                <h2 id="solution-2-cache-busting-for-external-packages">Solution 2: Cache Busting for External Packages</h2>

                <p>But what about packages not in your lock file? Maybe you have internal GitHub packages that follow branch conventions (e.g., <code>org/analytics-core@1.4-dev</code>). These update frequently, but your lock file doesn't track their commits.</p>

                <p>Docker needs a signal that something changed. We give it one:</p>

                <pre><code class="language-dockerfile"># Main Dockerfile
ARG BASE_IMAGE
ARG CACHE_BUST=0

FROM ${BASE_IMAGE} AS builder

# This layer rebuilds when CACHE_BUST changes
RUN echo "Cache bust: ${CACHE_BUST}" && \
    R -e "renv::install('org/analytics-core@${BRANCH}')"</code></pre>

                <p>The <code>echo</code> statement is the key. Docker evaluates build args, sees that <code>CACHE_BUST</code> changed, and invalidates this layer and everything after it.</p>

                <p>In your CI:</p>

                <pre><code class="language-yaml">build-args: |
  BASE_IMAGE=registry.example.com/${BASE_TAG}
  CACHE_BUST=${{ github.run_id }}</code></pre>

                <p>Using <code>github.run_id</code> means every build gets fresh external packages. But you can also make it smarter:</p>

                <pre><code class="language-yaml"># Only bust cache when triggered by upstream repo webhook
cache-bust: ${{ inputs.cache-bust || 'stable' }}</code></pre>

                <p>This way, normal PRs use cached packages (fast), but when an upstream repo dispatches a workflow trigger, you pass a new cache-bust value and force a fresh install.</p>

                <h2 id="solution-3-tests-as-build-gates">Solution 3: Tests as Build Gates</h2>

                <p>Here's a pattern I wish I'd adopted earlier: make your Docker build fail if tests fail. Not "build the image, then run tests in a separate job." The image literally doesn't get created unless tests pass.</p>

                <pre><code class="language-dockerfile"># Dockerfile - Multi-stage with test gate
ARG BASE_IMAGE

# Stage 1: Build and Test
FROM ${BASE_IMAGE} AS builder

COPY . /app/
WORKDIR /app

# Install branch-specific packages
RUN R -e "renv::install('org/package@${BRANCH}')"

# Run tests - build FAILS if tests fail
# JUnit reporter writes XML for CI systems to parse
RUN R -e "testthat::test_dir('tests/testthat', \
    reporter = testthat::JunitReporter\$new(file = '/tmp/test-results.xml'), \
    stop_on_failure = TRUE)"

# Verify results were generated
RUN test -f /tmp/test-results.xml || exit 1


# Stage 2: Production Runtime
FROM rocker/r2u:24.04 AS runtime

WORKDIR /app

# Copy ONLY production artifacts (no tests/)
COPY --from=builder /app/renv/ /app/renv/
COPY --from=builder /app/R/ /app/R/
COPY --from=builder /app/global.R /app/
COPY --from=builder /app/server.R /app/
COPY --from=builder /app/ui.R /app/

# Note: tests/ directory stays in builder stage - not copied to runtime</code></pre>

                <p>The key insight: <code>stop_on_failure = TRUE</code> makes <code>testthat::test_dir()</code> return a non-zero exit code when tests fail, which causes the <code>RUN</code> instruction to fail, which stops the entire build. No tests passing = no image.</p>

                <p><strong>Extracting test results</strong>: The tricky part is getting JUnit XML out of a failed build for CI reporting. You need to build just the builder stage, then copy the results out:</p>

                <pre><code class="language-yaml">- name: Extract test results
  if: always()  # Run even if build failed
  run: |
    # Build only the builder stage (continues even if tests failed)
    docker build --target builder -t temp-builder . || true

    # Create container and copy results out
    docker create --name temp temp-builder
    docker cp temp:/tmp/test-results.xml ./test-results.xml || true
    docker rm temp

- name: Upload test results
  if: always()
  uses: actions/upload-artifact@v4
  with:
    name: test-results
    path: test-results.xml</code></pre>

                <h2 id="putting-it-all-together">Putting It All Together</h2>

                <p>Here's the flow:</p>

                <pre><code>PR Opened
    │
    ▼
┌─────────────────────────────────────┐
│ Compute renv.lock hash              │
│ Check if base image exists in ACR   │
└─────────────────────────────────────┘
    │
    ├── Cache HIT ──────────────────────┐
    │                                   │
    ▼                                   ▼
┌──────────────────┐          ┌─────────────────────────┐
│ Build base image │          │ Skip base build         │
│ (~15 min)        │          │ (0 sec)                 │
└──────────────────┘          └─────────────────────────┘
    │                                   │
    └───────────────┬───────────────────┘
                    ▼
        ┌───────────────────────┐
        │ Build app image       │
        │ • Install GH packages │
        │ • Run tests           │
        │ • Build runtime       │
        └───────────────────────┘
                    │
        ┌───────────┴───────────┐
        │                       │
        ▼                       ▼
   Tests PASS            Tests FAIL
        │                       │
        ▼                       ▼
   Push image            Build aborts
   to registry           No image created</code></pre>

                <h2 id="results">Results</h2>

                <table class="blog-table">
                    <thead>
                        <tr>
                            <th>Scenario</th>
                            <th>Before</th>
                            <th>After</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>PR with no dependency changes</td>
                            <td>18-22 min</td>
                            <td>4-6 min</td>
                        </tr>
                        <tr>
                            <td>PR with renv.lock changes</td>
                            <td>18-22 min</td>
                            <td>18-22 min (expected)</td>
                        </tr>
                        <tr>
                            <td>Base image cache hit rate</td>
                            <td>0%</td>
                            <td>~85%</td>
                        </tr>
                        <tr>
                            <td>Test failures caught pre-push</td>
                            <td>0%</td>
                            <td>100%</td>
                        </tr>
                    </tbody>
                </table>

                <p>The biggest win isn't even the time savings—it's confidence. When an image exists in the registry, you <em>know</em> it passed tests. No more "the tests ran in a separate job that we forgot to check."</p>

                <h2 id="things-that-broke-along-the-way">Things That Broke Along the Way</h2>

                <p><strong>1. Registry authentication timing</strong>: We tried checking if the base image exists <em>before</em> logging into the container registry. Obvious in hindsight.</p>

                <p><strong>2. Disk space on runners</strong>: Building both base and app images in one job exhausted GitHub runner disk space. We added conditional cleanup—aggressive cleanup only when base image needs building.</p>

                <p><strong>3. Test result extraction from failed builds</strong>: <code>docker build</code> exits non-zero when tests fail, so the container never gets created. The fix is <code>--target builder</code> to build just that stage, ignoring the runtime stage that depends on test success.</p>

                <h2 id="whats-next">What's Next</h2>

                <p>This setup handles unit tests, but integration tests—especially for Shiny apps with browser interactions—are a different beast. That's Part 3: running headless Chrome in Docker for <code>shinytest2</code> without wanting to throw your laptop out the window.</p>

                <hr>

                <p><em>This is Part 2 of a series on Docker optimization for R Shiny applications. <a href="docker-optimization.html">Part 1</a> covers multistage builds and layer caching fundamentals.</em></p>
      ]]></description>
    </item>

    <item>
      <title>Optimizing R Shiny Docker Builds: Warm vs Cold Build Strategy</title>
      <link>https://sumedhsankhe.github.io/blog/posts/docker-optimization.html</link>
      <guid isPermaLink="true">https://sumedhsankhe.github.io/blog/posts/docker-optimization.html</guid>
      <pubDate>Mon, 16 Dec 2025 00:00:00 GMT</pubDate>
      <author>noreply@sumedhsankhe.github.io (Sumedh R. Sankhe)</author>
      <category>Docker</category>
      <category>R</category>
      <category>Shiny</category>
      <category>DevOps</category>
      <category>Performance</category>
      <category>Kubernetes</category>
      <category>SaaS</category>
      <description><![CDATA[
                <p class="blog-intro">This is my first time writing up a technical blog post, so bear with me. I'm going to share what we learned optimizing Docker builds for R Shiny apps, including the things that broke along the way.</p>

                <p>At Alamar Biosciences, I work on the NULISA Analysis Software (NAS) - a <strong>large-scale, customer-facing SaaS application</strong> for analyzing proteomics data, built with R Shiny and running on Azure Kubernetes Service (AKS). NAS is used by customers across academia and industry worldwide as a free cloud service. Unlike typical internal Shiny apps deployed with Posit Connect, NAS serves external customers directly, which means deployment speed, reliability, and scalability are critical for customer satisfaction and platform availability.</p>

                <p>Our Docker builds were taking 20-25 minutes. Every. Single. Build. It didn't matter if you changed one line of code or overhauled the entire data processing pipeline—Docker would reinstall all 200+ R packages from scratch. A simple bug fix? Wait 25 minutes. Testing a UI tweak? Another 25 minutes. Our images were pushing 1.5GB compressed to Azure Container Registry. When you're shipping features to customers and fixing production bugs, treating every build the same kills your velocity.</p>

                <p>This post walks through the optimizations we implemented in late 2025 that fundamentally changed how we build Docker images. The key insight: <strong>separate code changes from dependency changes</strong>. Now, the common case (code changes) builds in 8-15 minutes—a 60-68% improvement—while dependency updates take longer (40 mins) but happen infrequently. We also reduced image sizes by 42% (1.5GB → 870MB compressed in ACR). The optimization involves splitting stable CRAN dependencies into a base image, leveraging rocker/r2u for binary package installation, and properly structuring multistage builds. More importantly, this post covers the things that broke along the way and how we fixed them.</p>

                <h2 id="the-problem">The Problem: Slow, Bloated Docker Images</h2>

                <p>Our original Dockerfile followed a common pattern—straightforward but inefficient:</p>

                <pre><code class="language-dockerfile">FROM rocker/r2u:24.04

# Install system dependencies
RUN apt-get update && apt-get install -y \
    libcurl4-openssl-dev \
    libssl-dev \
    libxml2-dev \
    # ... many more -dev packages

WORKDIR /app

# Copy everything at once
COPY . .

# Install R packages
RUN R -e "install.packages('renv')"
RUN R -e "renv::restore()"

EXPOSE 3838
CMD ["R", "-e", "shiny::runApp('/app', host='0.0.0.0', port=3838)"]</code></pre>

                <p>This approach had three big problems:</p>

                <h3>Problem 1: Poor Layer Caching</h3>

                <p>Any change to our application code—even fixing a typo in <code>app.R</code>—would invalidate the <code>renv::restore()</code> layer. Docker would reinstall ALL 200+ R packages from scratch. We're talking the usual suspects like <code>ggplot2</code>, <code>plotly</code>, <code>DT</code>, plus a ton of domain-specific proteomics packages, and 2 custom in-house packages. Every. Single. Time. On our GitHub Actions runners, that's 60+ minutes of watching packages compile and tests run.</p>

                <h3>Problem 2: Bloated Production Images</h3>

                <p>Our final images had everything needed to build the app, not just run it. All the build tools like <code>gcc</code>, <code>make</code>, and those <code>-dev</code> system libraries were just sitting there in production taking up space. The result? Nearly 2GB uncompressed images when the actual runtime stuff could be much smaller.</p>

                <h3>Problem 3: Slow CI/CD Pipelines</h3>

                <p>Here's what our Azure Kubernetes deployment looked like:</p>
                <ol>
                    <li>Push a code change (bug fix, new feature, etc.)</li>
                    <li>GitHub Actions starts building</li>
                    <li>Wait 20-25 minutes (go get coffee, check Slack, lose focus)</li>
                    <li>Push to Azure Container Registry</li>
                    <li>Deploy to AKS</li>
                </ol>

                <p>Those build times killed productivity. You'd push a fix, then switch to something else while waiting. By the time the build finished, you'd forgotten what you were even working on. It was like waiting for a Wonder to be built while your opponents are rushing you with trebuchets.</p>

                <p><strong>Why this matters for SaaS:</strong> With Posit Connect, you typically deploy once and iterate internally. With a customer-facing SaaS on Kubernetes, you're constantly shipping features, bug fixes, and updates. Fast build times directly impact how quickly you can respond to customer issues and ship improvements. A 25-minute build cycle for every code change means you can only deploy a handful of times per day. That's not acceptable for modern SaaS development.</p>

                <h2 id="the-solution">The Solution: Multistage Docker Builds</h2>

                <p>The fix involves three core strategies (think of it as your build order):</p>

                <ol>
                    <li><strong>Separate build from runtime</strong> using Docker multistage builds</li>
                    <li><strong>Optimize layer caching</strong> by copying dependencies before code</li>
                    <li><strong>Minimize runtime dependencies</strong> to only what's needed to run the app</li>
                </ol>

                <p>Let me show you exactly how this works. If you're familiar with AoE2, this is basically advancing from Dark Age (single-stage mess) to Imperial Age (optimized multistage build).</p>

                <h2 id="implementation">Implementation: Building the Optimized Dockerfile</h2>

                <p>I'm going to walk through the multistage Dockerfile step by step. In the demo repo, I have a simple two-stage version for the example app. But for NAS, we actually use a three-stage build that separates CRAN packages from our custom packages. This makes sense when you have custom packages that change more frequently than your CRAN dependencies. For simpler apps, two stages is plenty.</p>

                <h3>Stage 1: The Builder</h3>

                <p>This stage compiles all the packages and prepares the app. In our real NAS setup, this is where we also install custom packages and run unit tests (unit testing in Docker builds deserves its own blog post, so I won't dive into that here):</p>

                <pre><code class="language-dockerfile"># ============ STAGE 1: Builder ============
FROM rocker/r2u:24.04 AS builder

# Configure renv cache to use consistent path across stages
ENV RENV_PATHS_CACHE="/app/renv/.cache"

# Install build dependencies (with -dev packages)
RUN apt-get update && apt-get install -y \
    libcurl4-openssl-dev \
    libssl-dev \
    libxml2-dev \
    libfontconfig1-dev \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# CRITICAL: Copy ONLY dependency files first
COPY renv.lock renv.lock
COPY .Rprofile .Rprofile
COPY renv/activate.R renv/activate.R
COPY renv/settings.json renv/settings.json

# Install packages - this layer is cached unless renv.lock changes
RUN R -e "install.packages('renv', repos='https://cloud.r-project.org')"
RUN R -e "renv::restore()"

# Copy application code AFTER dependencies are installed
# This means code changes don't invalidate the package layer
COPY app.R app.R</code></pre>

                <p><strong>The key part:</strong> Notice how we copy <code>renv.lock</code> and the renv files separately from <code>app.R</code>. Your lockfile only changes when you add or remove packages (maybe once a week?). Your application code changes constantly (multiple times a day). By separating them, Docker can cache the expensive <code>renv::restore()</code> step and skip it when you only change your app code.</p>

                <h3>Stage 2: The Runtime</h3>

                <p>Now we build a clean runtime image that only has what's needed to run the app:</p>

                <pre><code class="language-dockerfile"># ============ STAGE 2: Runtime ============
FROM rocker/r2u:24.04

# Configure renv cache to match builder stage
ENV RENV_PATHS_CACHE="/app/renv/.cache"

# Install ONLY runtime libraries (no -dev packages)
RUN apt-get update && apt-get install -y \
    libcurl4 \
    libssl3 \
    libxml2 \
    libfontconfig1 \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Copy the compiled renv library from builder (includes cache)
COPY --from=builder /app/renv /app/renv
COPY --from=builder /app/.Rprofile /app/.Rprofile
COPY --from=builder /app/renv.lock /app/renv.lock

# Copy application code
COPY --from=builder /app/app.R /app/app.R

EXPOSE 3838
CMD ["R", "--vanilla", "-e", ".libPaths('/app/renv/library/linux-ubuntu-noble/R-4.5/x86_64-pc-linux-gnu'); shiny::runApp('/app', host='0.0.0.0', port=3838)"]</code></pre>

                <p><strong>What's happening here:</strong> The runtime stage starts fresh and uses <code>COPY --from=builder</code> to grab the compiled packages. Notice we're installing <code>libcurl4</code> instead of <code>libcurl4-openssl-dev</code>. The <code>-dev</code> packages include headers and build tools. We don't need those to run the app, only to compile packages. This alone saves hundreds of megabytes.</p>

                <p>Also notice the CMD uses <code>--vanilla</code> - that's the fix for the renv runtime issue I mentioned earlier.</p>

                <h2 id="things-broke">Things That Broke (And How I Fixed Them)</h2>

                <p>Okay, so I thought I was done after writing the multistage Dockerfile. Built the images, they looked great. Then I actually tried to run them and... the app wouldn't start. Here's what went wrong.</p>

                <h3>Issue 1: renv Trying to Reinstall Packages at Runtime</h3>

                <p>The containers would start, but then renv would activate (because of <code>.Rprofile</code>) and immediately complain that packages were missing or out of sync. It would try to reinstall everything at runtime. Turns out my <code>renv.lock</code> file was missing a bunch of transitive dependencies - things like <code>cpp11</code>, <code>crosstalk</code>, <code>farver</code>. These aren't packages I explicitly use, but they're dependencies of dependencies.</p>

                <p>When renv detected these weren't in the lockfile, it thought something was wrong and tried to "fix" it by reinstalling. In a running container. Which obviously failed.</p>

                <p><strong>The fix:</strong> I disabled renv activation at runtime by using <code>R --vanilla</code> which skips the <code>.Rprofile</code>. Then I explicitly set the library path in the CMD:</p>

                <pre><code class="language-dockerfile">CMD ["R", "--vanilla", "-e", ".libPaths('/app/renv/library/linux-ubuntu-noble/R-4.5/x86_64-pc-linux-gnu'); shiny::runApp('/app', host = '0.0.0.0', port = 3838)"]</code></pre>

                <p>This way, R uses the pre-installed packages but doesn't trigger renv's "helpful" automatic restoration.</p>

                <h3>Issue 2: Broken Symlinks in Multistage Builds</h3>

                <p>Even after fixing the renv activation issue, the multistage builds still wouldn't work. Shiny couldn't find any packages. Turns out renv uses symlinks to a cache directory at <code>/root/.cache/R/renv/cache/</code>. When I copied the renv library between stages, I was copying the symlinks but not the actual files they pointed to. So every package was just a broken link.</p>

                <p>I spent way too long debugging this before I realized what was happening.</p>

                <p><strong>The fix:</strong> Copy the renv cache along with the library:</p>

                <pre><code class="language-dockerfile"># Copy the renv cache (symlinks in renv/library point to this cache)
COPY --from=builder /root/.cache/R/renv /root/.cache/R/renv</code></pre>

                <p>Now the symlinks work and packages load properly.</p>

                <h3>Lesson Learned</h3>

                <p>Test your containers actually run, not just build. I wasted a couple hours assuming that if the build succeeded, everything was fine. Docker's multistage builds add complexity, especially with package managers that use caching strategies like renv. Don't be like me clicking "I'm ready!" before actually being ready - test your builds like you're scouting your opponent's base before committing to a strategy.</p>

                <h2 id="results">Results: Quantified Performance Improvements</h2>

                <p>Here are the real numbers from our GitHub Actions workflow on the demo repo:</p>

                <table class="blog-table">
                    <thead>
                        <tr>
                            <th>Metric</th>
                            <th>Single-Stage</th>
                            <th>Two-Stage</th>
                            <th>Three-Stage</th>
                            <th>Improvement</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>Image size (GHCR)</strong></td>
                            <td>1.27 GB</td>
                            <td>948 MB</td>
                            <td>948 MB</td>
                            <td><strong>25% smaller</strong></td>
                        </tr>
                        <tr>
                            <td><strong>Warm build</strong> (code change only)</td>
                            <td>5-7 mins</td>
                            <td>~30s</td>
                            <td>~30s</td>
                            <td><strong>92-94% faster</strong></td>
                        </tr>
                        <tr>
                            <td><strong>Cold build</strong> (no cache)</td>
                            <td>8-10 mins</td>
                            <td>6-8 mins</td>
                            <td>6-8 mins</td>
                            <td>20-25% faster</td>
                        </tr>
                    </tbody>
                </table>

                <p>For our production NAS application with 200+ CRAN packages and 2 custom in-house packages:</p>

                <table class="blog-table">
                    <thead>
                        <tr>
                            <th>Metric</th>
                            <th>Before (NAS 1.3)</th>
                            <th>After (NAS 1.4)</th>
                            <th>Improvement</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>Image size (ACR compressed)</strong></td>
                            <td>1.5 GB</td>
                            <td>870 MB</td>
                            <td><strong>42% smaller</strong></td>
                        </tr>
                        <tr>
                            <td><strong>Warm build</strong> (code change only)</td>
                            <td>20-25 mins</td>
                            <td>8-15 mins</td>
                            <td><strong>60-68% faster</strong></td>
                        </tr>
                        <tr>
                            <td><strong>Cold build</strong> (dependency change)</td>
                            <td>20-25 mins</td>
                            <td>40 mins</td>
                            <td>Slower, but infrequent</td>
                        </tr>
                    </tbody>
                </table>

                <div class="blog-note">
                    <p><strong>Note:</strong> Our production setup includes additional optimizations beyond the scope of this post: automated base image rebuilds triggered by renv.lock hash changes, cache-busting strategies for custom package updates, and GitHub Actions runner cleanup for multi-stage builds. These advanced CI/CD integrations will be covered in a follow-up post.</p>
                </div>

                <div class="blog-note">
                    <p><strong>Note on image sizes:</strong> The sizes shown are <strong>compressed sizes</strong> as stored in container registries (ACR/GHCR). These are the sizes that matter for:</p>
                    <ul>
                        <li>Registry storage costs</li>
                        <li>Network transfer time during push/pull</li>
                        <li>Initial deployment speed to Kubernetes</li>
                    </ul>
                    <p>Container registries compress images to about 25-35% of their uncompressed size. So the 870MB compressed NAS image is ~2.2-2.6GB when uncompressed on disk. The demo app achieves a 25% reduction in registry size, while our production NAS app sees a 42% reduction (1.5GB → 870MB in ACR).</p>
                </div>

                <div class="blog-note">
                    <p><strong>Note on warm vs cold builds:</strong> The key optimization is <strong>distinguishing between these two scenarios</strong>. Our original setup treated every build the same—changing one line of code triggered a full 20-25 minute rebuild with all packages reinstalled. The optimized approach separates:</p>
                    <ul>
                        <li><strong>Warm builds</strong> (90% of builds): Code changes only → 8-15 mins</li>
                        <li><strong>Cold builds</strong> (10% of builds): Dependency changes → 40 mins (longer, but comprehensive and cached)</li>
                    </ul>
                    <p>Yes, cold builds are now slower, but they happen rarely (when you add/update packages). The common case (shipping code) is 60-68% faster.</p>
                </div>

                <p>The full CI/CD pipeline includes additional steps beyond the Docker build: running unit tests, extracting test results, publishing them to GitHub, security scanning, etc. That's why the end-to-end time is longer than just the Docker build. The unit testing integration will be covered in a separate blog post.</p>

                <h2 id="layer-caching">How Layer Caching Actually Works</h2>

                <p>This took me a while to really understand, so let me break it down. Each <code>RUN</code>, <code>COPY</code>, or <code>ADD</code> instruction in a Dockerfile creates a new layer. Docker caches these layers and reuses them if:</p>

                <ol>
                    <li>The instruction hasn't changed</li>
                    <li>All previous layers are unchanged</li>
                    <li>For <code>COPY</code>, the file contents are identical</li>
                </ol>

                <p><strong>The wrong way (what I had originally):</strong></p>
                <pre><code class="language-dockerfile">COPY . .                    # Any file change invalidates this
RUN R -e "renv::restore()"  # So this has to run again. Every time.</code></pre>

                <p><strong>The right way:</strong></p>
                <pre><code class="language-dockerfile">COPY renv.lock .            # Only changes when you add/remove packages (COLD build)
RUN R -e "renv::restore()"  # Gets cached and reused for code changes (enables WARM builds)
COPY app.R .                # Changes all the time, but doesn't break cache above (WARM build)</code></pre>

                <p>That simple reordering creates the warm/cold build distinction:</p>
                <ul>
                    <li><strong>Warm build</strong>: <code>app.R</code> changes, <code>renv.lock</code> unchanged → <code>renv::restore()</code> layer is cached, build takes 30s</li>
                    <li><strong>Cold build</strong>: <code>renv.lock</code> changes → <code>renv::restore()</code> runs, takes 6-8 mins for the demo app (40 mins for NAS with 200+ packages)</li>
                </ul>

                <p>Put your stable stuff first, your frequently changing stuff last.</p>

                <h2 id="production">How This Works in Production</h2>

                <p>Here's how this fits into our actual Azure Kubernetes pipeline:</p>

                <pre><code class="language-yaml"># .github/workflows/deploy.yml (simplified)
name: Build and Deploy to AKS

on:
  push:
    branches: [main]

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Build Docker image
        run: |
          docker build \
            -f Dockerfile.multistage \
            -t nasapp:${{ github.sha }} \
            --cache-from nasapp:latest \
            .

      - name: Push to ACR
        run: |
          docker tag nasapp:${{ github.sha }} \
            ${{ secrets.ACR_NAME }}.azurecr.io/nasapp:${{ github.sha }}
          docker push ${{ secrets.ACR_NAME }}.azurecr.io/nasapp:${{ github.sha }}</code></pre>

                <p>The <code>--cache-from</code> flag helps Docker reuse layers from previous builds, which makes the caching even better.</p>

                <h2 id="other-tips">Other Things That Helped</h2>

                <p>Once I got the basic multistage build working, here are some other tricks I picked up:</p>

                <h3>1. BuildKit and Build Secrets</h3>

                <p>If you have private R packages (we do), you need to pass GitHub PATs or other credentials. Don't bake them into your image:</p>

                <pre><code class="language-dockerfile"># syntax=docker/dockerfile:1

RUN --mount=type=secret,id=github_pat \
    GITHUB_PAT=$(cat /run/secrets/github_pat) \
    R -e "renv::restore()"</code></pre>

                <p>This keeps secrets out of your layers.</p>

                <h3>2. Pick the Right Base Image</h3>

                <p>Use <code>rocker/r2u</code> for significantly faster package installation through binary packages. This is especially beneficial for large projects with many dependencies.</p>

                <pre><code class="language-dockerfile">FROM rocker/r2u:24.04 AS builder</code></pre>

                <p>If you need Shiny Server (we don't - we use Kubernetes and run Shiny directly), <code>rocker/shiny</code> is also available with Shiny Server pre-installed. However, for Kubernetes deployments, <code>rocker/r2u</code> provides faster builds with smaller images.</p>

                <h2 id="learned">What I Learned</h2>

                <ol>
                    <li><strong>Test everything</strong>: Building successfully doesn't mean it runs successfully</li>
                    <li><strong>Measure what matters</strong>: I cared way more about warm rebuild time than cold build time - optimize for your actual gameplay, not theoretical perfect builds</li>
                    <li><strong>Order matters</strong>: Put stable stuff (dependencies) before frequently changing stuff (code)</li>
                    <li><strong>renv has quirks</strong>: It's great for reproducibility but you need to understand its caching and symlink behavior when containerizing</li>
                </ol>

                <h2 id="try-it">Try It Yourself</h2>

                <p>I put together a working example with all the code:</p>

                <p><strong>GitHub Repository</strong>: <a href="https://github.com/SumedhSankhe/shiny-docker-optimization" target="_blank" rel="noopener noreferrer">shiny-docker-optimization</a></p>

                <p>It includes:</p>
                <ul>
                    <li>A simple Shiny app (mtcars dashboard, nothing fancy)</li>
                    <li>Three Dockerfiles: single-stage (bad), multistage (better), and three-stage (for complex apps)</li>
                    <li>Full renv setup that actually works</li>
                    <li>Scripts to test build times</li>
                </ul>

                <p>Note: This demo app is way simpler than NAS (a few packages vs 200+, no custom packages, no unit tests). But the principles are the same, and you can see the optimization benefits even on a small app.</p>

                <p>Clone it and compare the results:</p>

                <pre><code class="language-bash">git clone https://github.com/SumedhSankhe/shiny-docker-optimization.git
cd shiny-docker-optimization

# Build both versions
docker build -f Dockerfile.single-stage -t shiny-app:single .
docker build -f Dockerfile.multistage -t shiny-app:optimized .

# Compare sizes
docker images | grep shiny-app

# Run it
docker run -p 3838:3838 shiny-app:optimized
# Open localhost:3838</code></pre>

                <h2 id="wrapping-up">Wrapping Up</h2>

                <p>This was my first real dive into Docker optimization and I learned a lot. The multistage build approach is now what I use for all our Shiny apps at work. The principles apply to other languages too - separate build from runtime, order your layers carefully, and test that things actually run.</p>

                <p>If you're deploying Shiny apps in containers, hopefully this saves you some time and headache.</p>

                <hr>

                <p><strong>Found this helpful or have questions?</strong> Open an issue on the <a href="https://github.com/SumedhSankhe/shiny-docker-optimization" target="_blank" rel="noopener noreferrer">GitHub repo</a> or connect with me on <a href="https://linkedin.com/in/sankhe" target="_blank" rel="noopener noreferrer">LinkedIn</a>.</p>

                <p><strong>Some resources I found useful:</strong></p>
                <ul>
                    <li><a href="https://engineering-shiny.org/" target="_blank" rel="noopener noreferrer">Engineering Production-Grade Shiny Apps</a> - Great book on building real Shiny apps</li>
                    <li><a href="https://docs.docker.com/develop/dev-best-practices/" target="_blank" rel="noopener noreferrer">Docker Build Best Practices</a> - Official Docker docs</li>
                    <li><a href="https://rstudio.github.io/renv/" target="_blank" rel="noopener noreferrer">renv documentation</a> - Understanding how renv works helps a lot</li>
                </ul>
      ]]></description>
    </item>

  </channel>
</rss>
